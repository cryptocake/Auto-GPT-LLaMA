[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "auto_gpt_llama_plugin"
version = "0.1.0"
authors = [
  { name="cryptocake", email="cryptocake@users.noreply.github.com" },
]
description = "This is a plugin that bypasses Openai's API endpoint and connects with GPT-LLaMA, making it possible to run local models."
readme = "README.md"
requires-python = ">=3.8"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]
dependencies = ["abstract-singleton"]

[project.urls]
"Homepage" = "https://github.com/cryptocake/Auto-GPT-LLaMA"
"Bug Tracker" = "https://github.com/cryptocake/Auto-GPT-LLaMA"

[tool.black]
line-length = 88
target-version = ['py38']
include = '\.pyi?$'
extend-exclude = ""

[tool.isort]
profile = "black"

[tool.pylint.messages_control]
disable = "C0330, C0326"

[tool.pylint.format]
max-line-length = "88"